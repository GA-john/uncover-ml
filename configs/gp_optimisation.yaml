
# not currently implemented
# patchsize: 0

features:
  - name: my pickle files
    type: pickle
    files:
      covariates: features.pk
      targets: targets.pk
      rawcovariates: rawcovariates.csv
      rawcovariates_mask: rawcovariates_mask.csv
  - name: my features 1
    type: ordinal
    files:
#      - path: /home/sudipta/GA_data/GA-cover2/k_15v5.tif
#      - path: /home/sudipta/GA_data/GA-cover2/dem_foc2.tif
#      - path: /home/sudipta/GA_data/GA-cover2/relief_dems_3s_mosaic1.tif
#      - path: /home/sudipta/GA_data/GA-cover2/relief_twi_3s.tif
#      - directory: /home/sudipta/GA_data/GA-cover2
      - list: /home/sudipta/GA_data/GA-cover2/sirsam_covariates_ordinal.txt
    # transforms are performed in order
    transforms:
      - centre
      - standardise
    imputation: mean
  
  - name: my features 2
    type: categorical
    files:
      - list: /home/sudipta/GA_data/GA-cover2/sirsam_covariates_cat.txt
    transforms:
    imputation: nn

mask:
  file: /home/sudipta/GA_data/mask/old_mask_test.tif
  retain: 1

preprocessing:
  # imputation: none
  # imputation: gaus
  # imputation: nn
  imputation:
  transforms:
    # - whiten:
        # keep_fraction: 0.8

targets:
  file: /home/sudipta/GA_data/GA-cover2/geochem_sites.shp
  property: Na_ppm_i_1


clustering:
  file: /home/lb/data/GA-cover/geochem_sites_class1.shp
  property: class
  algorithm: kmeans
  arguments:
    n_classes: 12
    oversample_factor: 5

learning:
#     algorithm: sgdapproxgp
#     arguments:
#         target_transform: standardise
#         kern: rbf
#         lenscale: 1000
#         ard: True
#         maxiter: 100
#         nbases: 50
#         random_state: 1
    algorithm: randomforest
    arguments:
       n_estimators: 10
       target_transform: standardise
#       forests: 18
#       parallel: True
#       outdir: .


#n_components : int, float, None or string
#        Number of components to keep.
#        if n_components is not set all components are kept::
#        if n_components == 'mle' and svd_solver == 'full', Minka\'s MLE is used
#        to guess the dimension
#        if ``0 < n_components < 1`` and svd_solver == 'full', select the number
#        of components such that the amount of variance that needs to be
#        explained is greater than the percentage specified by n_components
#        n_components cannot be equal to n_features for svd_solver == 'arpack'.
# svd_solver: {'auto', 'full', 'arpack', 'randomized'}
# iterated power: int > 0 or 'auto'
# kde transform is not working yet

optimisation:
  algorithm: gp
#  featuretransforms:
#    pca:
#      n_components: [0.98]
#      whiten: [False, True]
#      svd_solver: ['auto']
#      iterated_power: ['auto']
  hyperparameters:
    # n_estimators: [10, 50, 200]  # use with randomforest and gradientboost
    kernel: {'rbf': [{length_scale: 0.01},
                     {length_scale: 0.1},
                     {length_scale: 1},
                     {length_scale: 10},
                     {length_scale: 100},],
             'matern': [{length_scale: 0.1, nu: 0.5},
                        {length_scale: 0.1, nu: 1.5},
                        {length_scale: 0.1, nu: 2.5},
                        # {length_scale: 0.1, nu: 'inf'},
                        ],}
    target_transform: ['identity', 'standardise', 'rank', 'logistic', 'sqrt']
  optimisation_output: optimisation.csv

prediction:
  quantiles: 0.95

validation:
#  #- feature_rank
#  - parallel
#  - k-fold:
#      folds: 5
#      random_seed: 1
  
output:
  directory: .

